{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm.autotvm.measure.measure_methods import set_cuda_target_arch\n",
    "set_cuda_target_arch('sm_75')\n",
    "\n",
    "# The sizes of inputs and filters\n",
    "batch = 256\n",
    "in_channel = 256\n",
    "out_channel = 512\n",
    "in_size = 14\n",
    "kernel = 3\n",
    "pad = 1\n",
    "stride = 1\n",
    "\n",
    "# Algorithm\n",
    "A = te.placeholder((in_size, in_size, in_channel, batch), name=\"A\")\n",
    "W = te.placeholder((kernel, kernel, in_channel, out_channel), name=\"W\")\n",
    "out_size = (in_size - kernel + 2 * pad) // stride + 1\n",
    "# Pad input\n",
    "Apad = te.compute(\n",
    "    (in_size + 2 * pad, in_size + 2 * pad, in_channel, batch),\n",
    "    lambda yy, xx, cc, nn: tvm.tir.if_then_else(\n",
    "        tvm.tir.all(yy >= pad, yy - pad < in_size, xx >= pad, xx - pad < in_size),\n",
    "        A[yy - pad, xx - pad, cc, nn],\n",
    "        tvm.tir.const(0.0, \"float32\"),\n",
    "    ),\n",
    "    name=\"Apad\",\n",
    ")\n",
    "# Create reduction variables\n",
    "rc = te.reduce_axis((0, in_channel), name=\"rc\")\n",
    "ry = te.reduce_axis((0, kernel), name=\"ry\")\n",
    "rx = te.reduce_axis((0, kernel), name=\"rx\")\n",
    "# Compute the convolution\n",
    "B = te.compute(\n",
    "    (out_size, out_size, out_channel, batch),\n",
    "    lambda yy, xx, ff, nn: te.sum(\n",
    "        Apad[yy * stride + ry, xx * stride + rx, rc, nn] * W[ry, rx, rc, ff], axis=[ry, rx, rc]\n",
    "    ),\n",
    "    name=\"B\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the memory hierarchy\n",
    "s = te.create_schedule(B.op)\n",
    "s[Apad].compute_inline()  # compute Apad inline\n",
    "AA = s.cache_read(Apad, \"shared\", [B])\n",
    "WW = s.cache_read(W, \"shared\", [B])\n",
    "AL = s.cache_read(AA, \"local\", [B])\n",
    "WL = s.cache_read(WW, \"local\", [B])\n",
    "BL = s.cache_write(B, \"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile consts\n",
    "tile = 8\n",
    "num_thread = 8\n",
    "block_factor = tile * num_thread\n",
    "step = 8\n",
    "vthread = 2\n",
    "\n",
    "# Get the GPU thread indices\n",
    "block_x = te.thread_axis(\"blockIdx.x\")\n",
    "block_y = te.thread_axis(\"blockIdx.y\")\n",
    "block_z = te.thread_axis(\"blockIdx.z\")\n",
    "thread_x = te.thread_axis((0, num_thread), \"threadIdx.x\")\n",
    "thread_y = te.thread_axis((0, num_thread), \"threadIdx.y\")\n",
    "thread_xz = te.thread_axis((0, vthread), \"vthread\", name=\"vx\")\n",
    "thread_yz = te.thread_axis((0, vthread), \"vthread\", name=\"vy\")\n",
    "\n",
    "# Split the workloads\n",
    "hi, wi, fi, ni = s[B].op.axis\n",
    "bz = s[B].fuse(hi, wi)\n",
    "by, fi = s[B].split(fi, factor=block_factor)\n",
    "bx, ni = s[B].split(ni, factor=block_factor)\n",
    "\n",
    "# Bind the iteration variables to GPU thread indices\n",
    "s[B].bind(bz, block_z)\n",
    "s[B].bind(by, block_y)\n",
    "s[B].bind(bx, block_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tyz, fi = s[B].split(fi, nparts=vthread)  # virtual thread split\n",
    "txz, ni = s[B].split(ni, nparts=vthread)  # virtual thread split\n",
    "ty, fi = s[B].split(fi, nparts=num_thread)\n",
    "tx, ni = s[B].split(ni, nparts=num_thread)\n",
    "s[B].reorder(bz, by, bx, tyz, txz, ty, tx, fi, ni)\n",
    "\n",
    "s[B].bind(tyz, thread_yz)\n",
    "s[B].bind(txz, thread_xz)\n",
    "s[B].bind(ty, thread_y)\n",
    "s[B].bind(tx, thread_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule BL local write\n",
    "s[BL].compute_at(s[B], tx)\n",
    "yi, xi, fi, ni = s[BL].op.axis\n",
    "ry, rx, rc = s[BL].op.reduce_axis\n",
    "rco, rci = s[BL].split(rc, factor=step)\n",
    "s[BL].reorder(rco, ry, rx, rci, fi, ni)\n",
    "\n",
    "# Attach computation to iteration variables\n",
    "s[AA].compute_at(s[BL], rx)\n",
    "s[WW].compute_at(s[BL], rx)\n",
    "s[AL].compute_at(s[BL], rci)\n",
    "s[WL].compute_at(s[BL], rci)\n",
    "\n",
    "# Schedule for A's shared memory load\n",
    "yi, xi, ci, ni = s[AA].op.axis\n",
    "ty, ci = s[AA].split(ci, nparts=num_thread)\n",
    "tx, ni = s[AA].split(ni, nparts=num_thread)\n",
    "_, ni = s[AA].split(ni, factor=4)\n",
    "s[AA].reorder(ty, tx, yi, xi, ci, ni)\n",
    "s[AA].bind(ty, thread_y)\n",
    "s[AA].bind(tx, thread_x)\n",
    "s[AA].vectorize(ni)  # vectorize memory load\n",
    "\n",
    "# Schedule for W's shared memory load\n",
    "yi, xi, ci, fi = s[WW].op.axis\n",
    "ty, ci = s[WW].split(ci, nparts=num_thread)\n",
    "tx, fi = s[WW].split(fi, nparts=num_thread)\n",
    "_, fi = s[WW].split(fi, factor=4)\n",
    "s[WW].reorder(ty, tx, yi, xi, ci, fi)\n",
    "s[WW].bind(ty, thread_y)\n",
    "s[WW].bind(tx, thread_x)\n",
    "s[WW].vectorize(fi)  # vectorize memory load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution: 5.697496 ms\n"
     ]
    }
   ],
   "source": [
    "func = tvm.build(s, [A, W, B], \"cuda\")\n",
    "dev = tvm.cuda(0)\n",
    "a_np = np.random.uniform(size=(in_size, in_size, in_channel, batch)).astype(A.dtype)\n",
    "w_np = np.random.uniform(size=(kernel, kernel, in_channel, out_channel)).astype(W.dtype)\n",
    "a = tvm.nd.array(a_np, dev)\n",
    "w = tvm.nd.array(w_np, dev)\n",
    "b = tvm.nd.array(np.zeros((out_size, out_size, out_channel, batch), dtype=B.dtype), dev)\n",
    "func(a, w, b)\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=1)\n",
    "print(\"Convolution: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
