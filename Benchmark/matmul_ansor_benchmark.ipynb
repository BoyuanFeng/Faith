{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te, auto_scheduler\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1' # 0 for A6000 on winnie, 1 for P6000 on winnie.\n",
    "from tvm.autotvm.measure.measure_methods import set_cuda_target_arch\n",
    "# set_cuda_target_arch('sm_75')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that fusing all computation into one graph is not supported yet on Ansor.\n",
    "# Check: https://discuss.tvm.apache.org/t/assertion-triggered-when-auto-scheduling/9613/4\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_not_supported_yet(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_lw = te.placeholder((length, dim_in, dim_out), name=\"x_lw\", dtype=dtype)\n",
    "    x_uw = te.placeholder((length, dim_in, dim_out), name=\"x_uw\", dtype=dtype)\n",
    "    x_lb = te.placeholder((length, dim_out), name=\"x_lb\", dtype=dtype)\n",
    "    x_ub = te.placeholder((length, dim_out), name=\"x_ub\", dtype=dtype)\n",
    "    \n",
    "    y_lw = te.placeholder((length, dim_in, dim_Y_out), name=\"y_lw\", dtype=dtype)\n",
    "    y_uw = te.placeholder((length, dim_in, dim_Y_out), name=\"y_uw\", dtype=dtype)\n",
    "    y_lb = te.placeholder((length, dim_Y_out), name=\"y_lb\", dtype=dtype)\n",
    "    y_ub = te.placeholder((length, dim_Y_out), name=\"y_ub\", dtype=dtype)\n",
    "    \n",
    "    W_pos = te.compute(\n",
    "        W.shape, \n",
    "        lambda i,j: te.if_then_else(W[i,j]>0, W[i,j], 0.),\n",
    "        name='w_pos'\n",
    "    )\n",
    "    W_neg = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]<=0, W[i,j], 0.), name='w_neg')\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_lb_1 = te.compute(\n",
    "        y_lb.shape,\n",
    "        lambda l, i: \n",
    "            te.sum(x_lb[l,dout] * W_pos[dout,i], axis=dout),\n",
    "        name='y_lb_1'\n",
    "    )\n",
    "    y_lb_2 = te.compute(\n",
    "        y_lb.shape,\n",
    "        lambda l, i: \n",
    "            te.sum(x_ub[l,dout] * W_neg[dout,i], axis=dout),\n",
    "        name='y_lb_2'\n",
    "    )\n",
    "    y_lb = te.compute(\n",
    "        y_lb.shape,\n",
    "        lambda l, i: y_lb_1[l,i]+y_lb_2[l,i],\n",
    "        name=\"y_lb\"\n",
    "    )\n",
    "\n",
    "    y_ub_1 = te.compute(\n",
    "        y_ub.shape,\n",
    "        lambda l, i: \n",
    "            te.sum(x_ub[l,dout] * W_pos[dout,i], axis=dout),\n",
    "        name='y_ub_1'\n",
    "    )\n",
    "    y_ub_2 = te.compute(\n",
    "        y_ub.shape,\n",
    "        lambda l, i: \n",
    "            te.sum(x_lb[l,dout] * W_pos[dout,i], axis=dout),\n",
    "        name='y_ub_2'\n",
    "    )\n",
    "    y_ub = te.compute(\n",
    "        y_ub.shape,\n",
    "        lambda l, i: y_ub_1[l,i]+y_ub_2[l,i],\n",
    "        name=\"y_ub\"\n",
    "    )\n",
    "\n",
    "    y_lw_1 = te.compute(\n",
    "        y_lw.shape,\n",
    "        lambda l, j, i: \n",
    "            te.sum(x_lw[l,j,dout] * W_pos[dout,i], axis=dout),\n",
    "        name='y_lw_1'\n",
    "    )\n",
    "    y_lw_2 = te.compute(\n",
    "        y_lw.shape,\n",
    "        lambda l, j, i: \n",
    "            te.sum(x_uw[l,j,dout] * W_neg[dout,i], axis=dout),\n",
    "        name='y_lw_2'\n",
    "    )\n",
    "    y_lw = te.compute(\n",
    "        y_lw.shape,\n",
    "        lambda l, j, i: y_lw_1[l,j,i] + y_lw_2[l,j,i],\n",
    "        name=\"y_lw\"\n",
    "    )\n",
    "\n",
    "    y_uw_1 = te.compute(\n",
    "        y_uw.shape,\n",
    "        lambda l, j, i: \n",
    "            te.sum(x_uw[l,j,dout] * W_pos[dout,i], axis=dout),\n",
    "        name='y_uw_1'\n",
    "    )\n",
    "    y_uw_2 = te.compute(\n",
    "        y_uw.shape,\n",
    "        lambda l, j, i: \n",
    "            te.sum(x_lw[l,j,dout] * W_neg[dout,i], axis=dout),\n",
    "        name='y_uw_2'\n",
    "    )\n",
    "    y_uw = te.compute(\n",
    "        y_uw.shape,\n",
    "        lambda l, j, i: y_uw_1[l,j,i] + y_uw_2[l,j,i],\n",
    "        name=\"y_uw\"\n",
    "    )\n",
    "\n",
    "    return [W, x_lw, x_uw, x_lb, x_ub, y_lw, y_uw, y_lb, y_ub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ansor does not support this type of kernel yet.\n",
    "# In particular, the y_lb = y_lb_1+y_lb_2 is not supported in the computation graph.\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_not_supported(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_lb = te.placeholder((length, dim_out), name=\"x_lb\", dtype=dtype)\n",
    "    x_ub = te.placeholder((length, dim_out), name=\"x_ub\", dtype=dtype)\n",
    "    y_lb = te.placeholder((length, dim_Y_out), name=\"y_lb\", dtype=dtype)\n",
    "    \n",
    "    W_pos = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]>0, W[i,j], 0.), name='w_pos')\n",
    "    W_neg = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]<=0, W[i,j], 0.), name='w_neg')\n",
    "\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_lb_1 = te.compute(\n",
    "        y_lb.shape,\n",
    "        lambda l, i: \n",
    "            te.sum(x_lb[l,dout] * W_pos[dout,i], axis=dout),\n",
    "        name='y_lb_1'\n",
    "    )\n",
    "    y_lb_2 = te.compute(\n",
    "        y_lb.shape,\n",
    "        lambda l, i: \n",
    "            te.sum(x_ub[l,dout] * W_neg[dout,i], axis=dout),\n",
    "        name='y_lb_2'\n",
    "    )\n",
    "    y_lb = te.compute(\n",
    "        y_lb.shape,\n",
    "        lambda l, i: y_lb_1[l,i]+y_lb_2[l,i],\n",
    "        name=\"y_lb\"\n",
    "    )\n",
    "\n",
    "    return [W, x_lb, y_lb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ansor does not report error for this version.\n",
    "# However, it takes 25 minutes but cannot generate 1 schedule.\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_stuck(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_lb = te.placeholder((length, dim_out), name=\"x_lb\", dtype=dtype)\n",
    "    x_ub = te.placeholder((length, dim_out), name=\"x_ub\", dtype=dtype)\n",
    "    y_lb_1 = te.placeholder((length, dim_Y_out), name=\"y_lb_1\", dtype=dtype)\n",
    "    y_lb_2 = te.placeholder((length, dim_Y_out), name=\"y_lb_2\", dtype=dtype)\n",
    "    \n",
    "    W_pos = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]>0, W[i,j], 0.), name='w_pos')\n",
    "    W_neg = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]<=0, W[i,j], 0.), name='w_neg')\n",
    "\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_lb_1 = te.compute(\n",
    "        y_lb_1.shape,\n",
    "        lambda l, i: \n",
    "            te.sum(x_lb[l,dout] * W_pos[dout,i], axis=dout),\n",
    "        name='y_lb_1'\n",
    "    )\n",
    "    y_lb_2 = te.compute(\n",
    "        y_lb_1.shape,\n",
    "        lambda l, i: \n",
    "            te.sum(x_ub[l,dout] * W_neg[dout,i], axis=dout),\n",
    "        name='y_lb_2'\n",
    "    )\n",
    "    # y_lb = te.compute(\n",
    "    #     y_lb.shape,\n",
    "    #     lambda l, i: y_lb_1[l,i]+y_lb_2[l,i],\n",
    "    #     name=\"y_lb\"\n",
    "    # )\n",
    "\n",
    "    return [W, x_lb, y_lb_1, y_lb_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ansor keeps reporting errors when compiling this kernel:\n",
    "#    Target has been reduced to 1 due to too many failures or duplications\n",
    "#    See: https://discuss.tvm.apache.org/t/autoscheduler-prints-target-has-been-reduced-to-1-due-to-too-many-failures-or-duplications-and-fails-to-tune/10774/4\n",
    "#    Also tried renaming operators. But it still stucks.\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_stuck2(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"I_1\", dtype=dtype)\n",
    "    x_lb = te.placeholder((length, dim_out), name=\"I_2\", dtype=dtype)\n",
    "    x_ub = te.placeholder((length, dim_out), name=\"I_3\", dtype=dtype)\n",
    "    \n",
    "    W_pos = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]>0, W[i,j], 0.), name='I_5')\n",
    "    W_neg = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]<=0, W[i,j], 0.), name='I_6')\n",
    "\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_lb = te.compute(\n",
    "        (length, dim_Y_out),\n",
    "        lambda l, i: \n",
    "            te.sum(x_lb[l,dout] * W_pos[dout,i] + x_ub[l,dout]*W_neg[dout,i], axis=dout),\n",
    "        name='Y_7'\n",
    "    )\n",
    "\n",
    "    return [W, x_lb, y_lb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the largest subgraph that is supported by Ansor.\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_lb_1(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_lb = te.placeholder((length, dim_out), name=\"x_lb\", dtype=dtype)\n",
    "\n",
    "    W_pos = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]>0, W[i,j], 0.), name='W_pos')\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_lb1 = te.compute(\n",
    "        (length, dim_Y_out),\n",
    "        lambda l, i: \n",
    "            te.sum(x_lb[l,dout] * W_pos[dout, i], axis=dout),\n",
    "        name='y_lb1'\n",
    "    )\n",
    "\n",
    "    return [W, x_lb, y_lb1]\n",
    "\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_lb_2(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_ub = te.placeholder((length, dim_out), name=\"x_lb\", dtype=dtype)\n",
    "    y_lb_1 = te.placeholder((length, dim_Y_out), name=\"y_lb_1\", dtype=dtype)\n",
    "    \n",
    "    W_neg = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]<=0, W[i,j], 0.), name='W_neg')\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_lb_2 = te.compute(\n",
    "        y_lb_1.shape,\n",
    "        lambda l, i: \n",
    "            te.sum(x_ub[l,dout] * W_neg[dout,i], axis=dout),\n",
    "        name='y_lb_2'\n",
    "    )\n",
    "    y_lb = te.compute(y_lb_1.shape, lambda l, i: y_lb_1[l,i]+y_lb_2[l,i], name=\"y_lb\")\n",
    "\n",
    "    return [W, x_ub, y_lb_1, y_lb]\n",
    "\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_ub_1(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_ub = te.placeholder((length, dim_out), name=\"x_ub\", dtype=dtype)\n",
    "    \n",
    "    W_pos = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]>0, W[i,j], 0.), name='W_pos')\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_ub_1 = te.compute(\n",
    "        (length, dim_Y_out),\n",
    "        lambda l, i: te.sum(x_ub[l,dout] * W_pos[dout, i], axis=dout),\n",
    "        name='y_ub_1'\n",
    "    )\n",
    "\n",
    "    return [W, x_ub, y_ub_1]\n",
    "\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_ub_2(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_lb = te.placeholder((length, dim_out), name=\"x_ub\", dtype=dtype)\n",
    "    y_ub_1 = te.placeholder((length, dim_Y_out), name=\"y_ub_1\", dtype=dtype)\n",
    "    \n",
    "    W_neg = te.compute(W.shape, lambda i,j: te.if_then_else(W[i,j]<=0, W[i,j], 0.), name='W_neg')\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_ub_2 = te.compute(\n",
    "        y_ub_1.shape,\n",
    "        lambda l, i: \n",
    "            te.sum(x_lb[l,dout] * W_neg[dout, i], axis=dout),\n",
    "        name='y_ub_2'\n",
    "    )\n",
    "    y_ub = te.compute(y_ub_1.shape, lambda l, i: y_ub_1[l,i]+y_ub_2[l,i], name=\"y_ub\")\n",
    "\n",
    "    return [W, x_lb, y_ub_1, y_ub]\n",
    "\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_lw_1(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_lw = te.placeholder((length, dim_in, dim_out), name=\"x_lw\", dtype=dtype)\n",
    "    \n",
    "    W_pos = te.compute(\n",
    "        W.shape, \n",
    "        lambda i,j: te.if_then_else(W[i,j]>0, W[i,j], 0.),\n",
    "        name='w_pos'\n",
    "    )\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_lw_1 = te.compute(\n",
    "        (length, dim_in, dim_Y_out),\n",
    "        lambda l, j, i: \n",
    "            te.sum(x_lw[l,j,dout] * W_pos[dout, i], axis=dout),\n",
    "        name='y_lw_1'\n",
    "    )\n",
    "\n",
    "    return [W, x_lw, y_lw_1]\n",
    "\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_lw_2(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_uw = te.placeholder((length, dim_in, dim_out), name=\"x_uw\", dtype=dtype)\n",
    "    y_lw_1 = te.placeholder((length, dim_in, dim_Y_out), name=\"y_lw_1\", dtype=dtype)\n",
    "    \n",
    "    W_neg = te.compute(\n",
    "        W.shape, \n",
    "        lambda i,j: te.if_then_else(W[i,j]<=0, W[i,j], 0.),\n",
    "        name='w_neg'\n",
    "    )\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_lw_2 = te.compute(\n",
    "        y_lw_1.shape,\n",
    "        lambda l, j, i: \n",
    "            te.sum(x_uw[l,j,dout] * W_neg[dout, i], axis=dout),\n",
    "        name='y_lw_2'\n",
    "    )\n",
    "    y_lw = te.compute(\n",
    "        y_lw_1.shape,\n",
    "        lambda l, j, i: y_lw_1[l,j,i] + y_lw_2[l,j,i],\n",
    "        name=\"y_lw\"\n",
    "    )\n",
    "\n",
    "    return [W, x_uw, y_lw_1, y_lw]\n",
    "\n",
    "\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_uw_1(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_uw = te.placeholder((length, dim_in, dim_out), name=\"x_uw\", dtype=dtype)\n",
    "    \n",
    "    W_pos = te.compute(\n",
    "        W.shape, \n",
    "        lambda i,j: te.if_then_else(W[i,j]>0, W[i,j], 0.),\n",
    "        name='w_pos'\n",
    "    )\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_uw_1 = te.compute(\n",
    "        (length, dim_in, dim_Y_out),\n",
    "        lambda l, j, i: \n",
    "            te.sum(x_uw[l,j,dout] * W_pos[dout, i], axis=dout),\n",
    "        name='y_uw_1'\n",
    "    )\n",
    "\n",
    "    return [W, x_uw, y_uw_1]\n",
    "\n",
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def verify_matmul_uw_2(length, dim_in, dim_out, dim_Y_out, dtype=\"float32\"):\n",
    "    W = te.placeholder((dim_out, dim_Y_out), name=\"W\", dtype=dtype)\n",
    "    x_lw = te.placeholder((length, dim_in, dim_out), name=\"x_lw\", dtype=dtype)\n",
    "    y_uw_1 = te.placeholder((length, dim_in, dim_Y_out), name=\"y_uw_1\", dtype=dtype)\n",
    "    \n",
    "    W_neg = te.compute(\n",
    "        W.shape, \n",
    "        lambda i,j: te.if_then_else(W[i,j]<=0, W[i,j], 0.),\n",
    "        name='w_neg'\n",
    "    )\n",
    "\n",
    "    dout = te.reduce_axis((0, dim_out), \"dout\")\n",
    "    y_uw_2 = te.compute(\n",
    "        y_uw_1.shape,\n",
    "        lambda l, j, i: \n",
    "            te.sum(x_lw[l,j,dout] * W_neg[dout, i], axis=dout),\n",
    "        name='y_lw_2'\n",
    "    )\n",
    "    y_uw = te.compute(\n",
    "        y_uw_1.shape,\n",
    "        lambda l, j, i: y_uw_1[l,j,i] + y_uw_2[l,j,i],\n",
    "        name=\"y_uw\"\n",
    "    )\n",
    "\n",
    "    return [W, x_lw, y_uw_1, y_uw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansor_tuner(func_pointer, func_args, log_file=\"ansor_autotuning.json\", target=tvm.target.Target(\"llvm\")):# (length, dim_in, dim_out, dim_Y_out)\n",
    "    # length = 2\n",
    "    # dim_in = dim_out = dim_Y_out = 64\n",
    "    task = tvm.auto_scheduler.SearchTask(func=func_pointer, args=func_args, target=target)\n",
    "\n",
    "    # Inspect the computational graph\n",
    "    # print(\"Computational DAG:\")\n",
    "    # print(task.compute_dag)\n",
    "\n",
    "    tune_option = auto_scheduler.TuningOptions(\n",
    "        num_measure_trials=1,\n",
    "        measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n",
    "        verbose=2,\n",
    "    )\n",
    "    # Run auto-tuning (search)\n",
    "    task.tune(tune_option)\n",
    "    # Apply the best schedule\n",
    "    sch, args = task.apply_best(log_file)\n",
    "    return sch, args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=2\n",
    "# dim_in = 512\n",
    "# dim_out = 512\n",
    "# dim_Y_out = 512\n",
    "dim_in = dim_out = dim_Y_out = 1024\n",
    "\n",
    "# target = tvm.target.Target(\"llvm\")\n",
    "target = tvm.target.Target(\"cuda\")\n",
    "\n",
    "W_np = np.random.uniform(size=(dim_out, dim_Y_out)).astype(np.float32)\n",
    "x_lb_np = np.random.uniform(size=(length, dim_out)).astype(np.float32)\n",
    "x_ub_np = np.random.uniform(size=(length, dim_out)).astype(np.float32)\n",
    "x_lw_np = np.random.uniform(size=(length, dim_in, dim_out)).astype(np.float32)\n",
    "x_uw_np = np.random.uniform(size=(length, dim_in, dim_out)).astype(np.float32)\n",
    "\n",
    "# dev = tvm.cpu()\n",
    "dev = tvm.cuda()\n",
    "W_tvm = tvm.nd.array(W_np, device=dev)\n",
    "x_lb_tvm = tvm.nd.array(x_lb_np, device=dev)\n",
    "x_ub_tvm = tvm.nd.array(x_ub_np, device=dev)\n",
    "x_lw_tvm = tvm.nd.array(x_lw_np, device=dev)\n",
    "x_uw_tvm = tvm.nd.array(x_uw_np, device=dev)\n",
    "y_lb_1_tvm = tvm.nd.empty((length, dim_Y_out), device=dev)\n",
    "y_lb_2_tvm = tvm.nd.empty((length, dim_Y_out), device=dev)\n",
    "y_lb_tvm = tvm.nd.empty((length, dim_Y_out), device=dev)\n",
    "y_ub_1_tvm = tvm.nd.empty((length, dim_Y_out), device=dev)\n",
    "y_ub_2_tvm = tvm.nd.empty((length, dim_Y_out), device=dev)\n",
    "y_ub_tvm = tvm.nd.empty((length, dim_Y_out), device=dev)\n",
    "y_lw_1_tvm = tvm.nd.empty((length, dim_in, dim_Y_out), device=dev)\n",
    "y_lw_2_tvm = tvm.nd.empty((length, dim_in, dim_Y_out), device=dev)\n",
    "y_lw_tvm = tvm.nd.empty((length, dim_in, dim_Y_out), device=dev)\n",
    "y_uw_1_tvm = tvm.nd.empty((length, dim_in, dim_Y_out), device=dev)\n",
    "y_uw_2_tvm = tvm.nd.empty((length, dim_in, dim_Y_out), device=dev)\n",
    "y_uw_tvm = tvm.nd.empty((length, dim_in, dim_Y_out), device=dev)\n",
    "\n",
    "# Evaluate execution time.\n",
    "def profile(func, func_args):\n",
    "    evaluator = func.time_evaluator(func.entry_name, dev, min_repeat_ms=500)\n",
    "    # \"Execution time of this operator in ms\"\n",
    "    return np.mean(evaluator(*func_args).results) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Sketches\t\t#s: 1\n",
      "Sample Initial Population\t#s: 99\tfail_ct: 1949\tTime elapsed: 0.65\n",
      "GA Iter: 0\tMax score: 0.9904\tMin score: 0.0070\t#Pop: 99\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 1.0000\tMin score: 0.9803\t#Pop: 128\t#M+: 1388\t#M-: 0\n",
      "EvolutionarySearch\t\t#s: 128\tTime elapsed: 6.37\n"
     ]
    }
   ],
   "source": [
    "lb_1_sch, lb_1_args = ansor_tuner(verify_matmul_lb_1, (length, dim_in, dim_out, dim_Y_out), log_file=\"verify_matmul_lb_1.json\", target=target)\n",
    "func_lb1 = tvm.build(lb_1_sch, lb_1_args, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Sketches\t\t#s: 1\n",
      "Sample Initial Population\t#s: 80\tfail_ct: 1968\tTime elapsed: 0.56\n",
      "GA Iter: 0\tMax score: 0.9968\tMin score: 0.0168\t#Pop: 80\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9999\tMin score: 0.9818\t#Pop: 128\t#M+: 1386\t#M-: 0\n",
      "EvolutionarySearch\t\t#s: 128\tTime elapsed: 6.64\n"
     ]
    }
   ],
   "source": [
    "lb_2_sch, lb_2_args = ansor_tuner(verify_matmul_lb_2, (length, dim_in, dim_out, dim_Y_out), log_file=\"verify_matmul_lb_2.json\", target=target)\n",
    "func_lb2 = tvm.build(lb_2_sch, lb_2_args, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Sketches\t\t#s: 1\n",
      "Sample Initial Population\t#s: 99\tfail_ct: 1949\tTime elapsed: 0.56\n",
      "GA Iter: 0\tMax score: 0.9904\tMin score: 0.0020\t#Pop: 99\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9999\tMin score: 0.9792\t#Pop: 128\t#M+: 1391\t#M-: 0\n",
      "EvolutionarySearch\t\t#s: 128\tTime elapsed: 6.54\n"
     ]
    }
   ],
   "source": [
    "ub_1_sch, ub_1_args = ansor_tuner(verify_matmul_ub_1, (length, dim_in, dim_out, dim_Y_out), log_file=\"verify_matmul_ub_1.json\", target=target)\n",
    "func_ub1 = tvm.build(ub_1_sch, ub_1_args, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Sketches\t\t#s: 1\n",
      "Sample Initial Population\t#s: 72\tfail_ct: 1976\tTime elapsed: 0.58\n",
      "GA Iter: 0\tMax score: 0.9991\tMin score: 0.0038\t#Pop: 72\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9996\tMin score: 0.9799\t#Pop: 128\t#M+: 1393\t#M-: 0\n",
      "EvolutionarySearch\t\t#s: 128\tTime elapsed: 6.58\n"
     ]
    }
   ],
   "source": [
    "ub_2_sch, ub_2_args = ansor_tuner(verify_matmul_ub_2, (length, dim_in, dim_out, dim_Y_out), log_file=\"verify_matmul_ub_2.json\", target=target)\n",
    "func_ub2 = tvm.build(ub_2_sch, ub_2_args, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Sketches\t\t#s: 1\n",
      "Sample Initial Population\t#s: 92\tfail_ct: 1956\tTime elapsed: 0.96\n",
      "GA Iter: 0\tMax score: 0.9919\tMin score: 0.0211\t#Pop: 92\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 1.0000\tMin score: 0.9814\t#Pop: 128\t#M+: 1388\t#M-: 0\n",
      "EvolutionarySearch\t\t#s: 128\tTime elapsed: 9.24\n"
     ]
    }
   ],
   "source": [
    "lw_1_sch, lw_1_args = ansor_tuner(verify_matmul_lw_1, (length, dim_in, dim_out, dim_Y_out), log_file=\"verify_matmul_lw_1.json\", target=target)\n",
    "func_lw1 = tvm.build(lw_1_sch, lw_1_args, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Sketches\t\t#s: 1\n",
      "Sample Initial Population\t#s: 103\tfail_ct: 1945\tTime elapsed: 0.97\n",
      "GA Iter: 0\tMax score: 0.9920\tMin score: 0.0326\t#Pop: 103\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9998\tMin score: 0.9814\t#Pop: 128\t#M+: 1388\t#M-: 0\n",
      "EvolutionarySearch\t\t#s: 128\tTime elapsed: 9.80\n"
     ]
    }
   ],
   "source": [
    "lw_2_sch, lw_2_args = ansor_tuner(verify_matmul_lw_2, (length, dim_in, dim_out, dim_Y_out), log_file=\"verify_matmul_lw_2.json\", target=target)\n",
    "func_lw2 = tvm.build(lw_2_sch, lw_2_args, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Sketches\t\t#s: 1\n",
      "Sample Initial Population\t#s: 82\tfail_ct: 1966\tTime elapsed: 0.92\n",
      "GA Iter: 0\tMax score: 0.9696\tMin score: 0.0090\t#Pop: 82\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 1.0000\tMin score: 0.9792\t#Pop: 128\t#M+: 1385\t#M-: 0\n",
      "EvolutionarySearch\t\t#s: 128\tTime elapsed: 9.50\n"
     ]
    }
   ],
   "source": [
    "uw_1_sch, uw_1_args = ansor_tuner(verify_matmul_uw_1, (length, dim_in, dim_out, dim_Y_out), log_file=\"verify_matmul_uw_1.json\", target=target)\n",
    "func_uw1 = tvm.build(uw_1_sch, uw_1_args, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Sketches\t\t#s: 1\n",
      "Sample Initial Population\t#s: 97\tfail_ct: 1951\tTime elapsed: 0.95\n",
      "GA Iter: 0\tMax score: 0.9886\tMin score: 0.0021\t#Pop: 97\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 1.0000\tMin score: 0.9822\t#Pop: 128\t#M+: 1400\t#M-: 0\n",
      "EvolutionarySearch\t\t#s: 128\tTime elapsed: 9.65\n"
     ]
    }
   ],
   "source": [
    "uw_2_sch, uw_2_args = ansor_tuner(verify_matmul_uw_2, (length, dim_in, dim_out, dim_Y_out), log_file=\"verify_matmul_uw_2.json\", target=target)\n",
    "func_uw2 = tvm.build(uw_2_sch, uw_2_args, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify_matmul_lb_1_latency:  0.026845218963939228 verify_matmul_lb_2_latency:  0.03377088577880027 verify_matmul_ub_1_latency:  0.032087939783818666 verify_matmul_ub_2_latency:  0.03510502681753386 verify_matmul_lw_1_latency:  0.9268270541474654 verify_matmul_lw_2_latency:  1.3374931604278075 verify_matmul_uw_1_latency:  0.8565199043570669 verify_matmul_uw_2_latency:  1.3420017754010696 total time:  4.590650965677502\n"
     ]
    }
   ],
   "source": [
    "verify_matmul_lb_1_latency = profile(func_lb1, (W_tvm, x_lb_tvm, y_lb_1_tvm))\n",
    "verify_matmul_lb_2_latency = profile(func_lb2, (W_tvm, x_ub_tvm, y_lb_1_tvm, y_lb_tvm))\n",
    "verify_matmul_ub_1_latency = profile(func_ub1, (W_tvm, x_ub_tvm, y_ub_1_tvm))\n",
    "verify_matmul_ub_2_latency = profile(func_ub2, (W_tvm, x_lb_tvm, y_ub_1_tvm, y_ub_tvm))\n",
    "verify_matmul_lw_1_latency = profile(func_lw1, (W_tvm, x_lw_tvm, y_lw_1_tvm))\n",
    "verify_matmul_lw_2_latency = profile(func_lw2, (W_tvm, x_uw_tvm, y_lw_1_tvm, y_lw_tvm))\n",
    "verify_matmul_uw_1_latency = profile(func_uw1, (W_tvm, x_uw_tvm, y_uw_1_tvm))\n",
    "verify_matmul_uw_2_latency = profile(func_uw2, (W_tvm, x_lw_tvm, y_uw_1_tvm, y_uw_tvm))\n",
    "\n",
    "print(\n",
    "    \"verify_matmul_lb_1_latency: \", verify_matmul_lb_1_latency,\n",
    "    \"verify_matmul_lb_2_latency: \", verify_matmul_lb_2_latency,\n",
    "    \"verify_matmul_ub_1_latency: \", verify_matmul_ub_1_latency,\n",
    "    \"verify_matmul_ub_2_latency: \", verify_matmul_ub_2_latency,\n",
    "    \"verify_matmul_lw_1_latency: \", verify_matmul_lw_1_latency,\n",
    "    \"verify_matmul_lw_2_latency: \", verify_matmul_lw_2_latency,\n",
    "    \"verify_matmul_uw_1_latency: \", verify_matmul_uw_1_latency,\n",
    "    \"verify_matmul_uw_2_latency: \", verify_matmul_uw_2_latency,\n",
    "    \"total time: \", verify_matmul_lb_1_latency + verify_matmul_lb_2_latency + verify_matmul_ub_1_latency + verify_matmul_ub_2_latency + verify_matmul_lw_1_latency + verify_matmul_lw_2_latency + verify_matmul_uw_1_latency + verify_matmul_uw_2_latency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /home/boyuan/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module c_relu_verification, skipping build step...\n",
      "Loading extension module c_relu_verification...\n",
      "pytorch. self.lb.shape:  torch.Size([1, 2, 1024])\n",
      "pytorch. w.shape:  torch.Size([1024, 1024])\n",
      "pytorch. W_pos:  tensor([[-0.0000, -0.0000, 0.0181,  ..., -0.0000, 0.4000, -0.0000],\n",
      "        [-0.0000, -0.0000, 0.3784,  ..., 0.4982, 0.3339, 0.3990],\n",
      "        [0.1272, 0.0037, 0.1144,  ..., -0.0000, 0.1197, -0.0000],\n",
      "        ...,\n",
      "        [0.2021, 0.3102, 0.2176,  ..., -0.0000, -0.0000, 0.4763],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [0.4370, -0.0000, 0.2924,  ..., -0.0000, 0.2635, 0.3885]],\n",
      "       device='cuda:0')\n",
      "pytorch. W_neg:  tensor([[-0.4813, -0.4038,  0.0000,  ..., -0.4719,  0.0000, -0.1915],\n",
      "        [-0.3211, -0.3797,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4999,  0.0000, -0.2483],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4760, -0.4486,  0.0000],\n",
      "        [-0.3470, -0.3841, -0.1534,  ..., -0.4660, -0.0611, -0.4725],\n",
      "        [ 0.0000, -0.1314,  0.0000,  ..., -0.2189,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "pytorch. y_lb1:  tensor([[[62.2549, 60.9371, 63.7881,  ..., 61.9803, 71.8310, 59.3868],\n",
      "         [63.1932, 61.6914, 62.2851,  ..., 62.7331, 67.6830, 59.9809]]],\n",
      "       device='cuda:0')\n",
      "pytorch. y_lb2:  tensor([[[-123.0411, -136.9298, -129.6456,  ..., -123.9776, -118.4495,\n",
      "          -132.7598],\n",
      "         [-121.6966, -133.1158, -129.8890,  ..., -126.4667, -119.9129,\n",
      "          -129.6606]]], device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      " pytorch. op_type: matmul, batch_size: 1, length: 2, dim_in: 1024, dim_out: 1024, average_time (ms): 9.80787181854248\n",
      "\n",
      "\n",
      "\n",
      "w_pos:  tensor([[-0.0000, -0.0000, 0.0181,  ..., -0.0000, 0.4000, -0.0000],\n",
      "        [-0.0000, -0.0000, 0.3784,  ..., 0.4982, 0.3339, 0.3990],\n",
      "        [0.1272, 0.0037, 0.1144,  ..., -0.0000, 0.1197, -0.0000],\n",
      "        ...,\n",
      "        [0.2021, 0.3102, 0.2176,  ..., -0.0000, -0.0000, 0.4763],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [0.4370, -0.0000, 0.2924,  ..., -0.0000, 0.2635, 0.3885]],\n",
      "       device='cuda:0')\n",
      "w_neg:  tensor([[-0.4813, -0.4038,  0.0000,  ..., -0.4719,  0.0000, -0.1915],\n",
      "        [-0.3211, -0.3797,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4999,  0.0000, -0.2483],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4760, -0.4486,  0.0000],\n",
      "        [-0.3470, -0.3841, -0.1534,  ..., -0.4660, -0.0611, -0.4725],\n",
      "        [ 0.0000, -0.1314,  0.0000,  ..., -0.2189,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "numpy lb1:  tensor([[[62.2549, 60.9371, 63.7881,  ..., 61.9803, 71.8310, 59.3868],\n",
      "         [63.1932, 61.6914, 62.2851,  ..., 62.7331, 67.6830, 59.9809]]],\n",
      "       device='cuda:0')\n",
      "numpy lb2:  tensor([[[-123.0411, -136.9298, -129.6456,  ..., -123.9776, -118.4495,\n",
      "          -132.7598],\n",
      "         [-121.6966, -133.1158, -129.8890,  ..., -126.4667, -119.9129,\n",
      "          -129.6606]]], device='cuda:0')\n",
      "numpy y_lb:  tensor([[[-60.7862, -75.9927, -65.8575,  ..., -61.9973, -46.6185, -73.3729],\n",
      "         [-58.5034, -71.4244, -67.6039,  ..., -63.7336, -52.2299, -69.6797]]],\n",
      "       device='cuda:0')\n",
      "pytorch lb:  tensor([[[-60.7862, -75.9927, -65.8575,  ..., -61.9973, -46.6185, -73.3729],\n",
      "         [-58.5034, -71.4244, -67.6039,  ..., -63.7336, -52.2299, -69.6797]]],\n",
      "       device='cuda:0')\n",
      "ansor lb:  [[-60.78618  -75.99264  -65.85749  ... -61.997295 -46.618477 -73.37297 ]\n",
      " [-58.50335  -71.424484 -67.60384  ... -63.733536 -52.230026 -69.679695]]\n",
      "lb_diff:  tensor(0.0020, device='cuda:0') , ub_diff:  tensor(0.0020, device='cuda:0') , lw_diff:  tensor(0., device='cuda:0') , uw_diff:  tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Check correctness\n",
    "# dim_out, dim_in, dim_Y_out has been set earlier\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "torch.manual_seed(1)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1' # 0 for A6000 on winnie, 1 for P6000 on winnie.\n",
    "sys.path.append('/home/boyuan/Faith-NNVerificationCompiler/HandTunedKernels/kernel_test/')\n",
    "import forward_test_bound\n",
    "\n",
    "import importlib\n",
    "importlib.reload(forward_test_bound)\n",
    "\n",
    "p = 2\n",
    "eps = 0.5\n",
    "batch_size = 1\n",
    "\n",
    "# Helper function for pytorch profiling\n",
    "def profile_pytorch(p, eps, lw, lb, uw, ub, w_input, other_bound, op_type='relu', num_profile=100):        \n",
    "    bound = forward_test_bound.Bounds(p, eps, lw, lb, uw, ub)\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    start.record()\n",
    "    for i in range(num_profile):\n",
    "        if op_type == 'relu':\n",
    "            bound_output = bound.relu()\n",
    "        elif op_type == 'matmul':\n",
    "            bound_output = bound.matmul(w_input)\n",
    "        elif op_type == 'dot_product':\n",
    "            bound_output = bound.dot_product(other_bound)\n",
    "\n",
    "    end.record()\n",
    "\n",
    "    # Waits for everything to finish running\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    average_time = start.elapsed_time(end)/num_profile # Unit: Millisecond\n",
    "    print(\"\\n\\n\\n pytorch. op_type: {}, batch_size: {}, length: {}, dim_in: {}, dim_out: {}, average_time (ms): {}\\n\\n\\n\".format(op_type, batch_size, length, dim_in, dim_out, average_time))\n",
    "    return bound_output\n",
    "\n",
    "# Get pytorch results\n",
    "device=\"cuda\"\n",
    "lb = torch.rand(1,length,dim_out).to(device)\n",
    "ub = lb + torch.rand(1,length,dim_out).to(device)\n",
    "lw = torch.rand(1,length,dim_in,dim_out).to(device) - 0.5\n",
    "uw = torch.rand(1,length,dim_in,dim_out).to(device) - 0.5\n",
    "\n",
    "w_input = torch.rand(dim_Y_out, dim_out).to(device) - 0.5\n",
    "other_bound = forward_test_bound.Bounds(p=2,eps=0.5,lw=lw,lb=lb,uw=uw,ub=ub)\n",
    "\n",
    "bound = profile_pytorch(p, eps, lw, lb, uw, ub, w_input, other_bound, op_type=\"matmul\", num_profile=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "w_input = w_input.t().contiguous()\n",
    "pos_mask = torch.gt(w_input, 0)\n",
    "w_pos = w_input * pos_mask\n",
    "w_neg = w_input - w_pos\n",
    "lb1 = lb.matmul(w_pos)\n",
    "lb2 = ub.matmul(w_neg)\n",
    "y_lb = lb1 + lb2\n",
    "\n",
    "\n",
    "print(\"w_pos: \", w_pos)\n",
    "print(\"w_neg: \", w_neg)\n",
    "print(\"numpy lb1: \", lb1)\n",
    "print(\"numpy lb2: \", lb2)\n",
    "print(\"numpy y_lb: \", y_lb)\n",
    "\n",
    "# Prepare ansor inputs\n",
    "# dev = tvm.cpu()\n",
    "dev = tvm.cuda()\n",
    "W_np = w_input.cpu().numpy()\n",
    "x_lb_np = lb.cpu().numpy()[0]\n",
    "x_ub_np = ub.cpu().numpy()[0]\n",
    "x_lw_np = lw.cpu().numpy()[0]\n",
    "x_uw_np = uw.cpu().numpy()[0]\n",
    "\n",
    "W_tvm = tvm.nd.array(W_np, device=dev)\n",
    "x_lb_tvm = tvm.nd.array(x_lb_np, device=dev)\n",
    "x_ub_tvm = tvm.nd.array(x_ub_np, device=dev)\n",
    "x_lw_tvm = tvm.nd.array(x_lw_np, device=dev)\n",
    "x_uw_tvm = tvm.nd.array(x_uw_np, device=dev)\n",
    "y_lb_1_tvm = tvm.nd.empty((length, dim_Y_out), device=dev)\n",
    "y_lb_tvm = tvm.nd.empty((length, dim_Y_out), device=dev)\n",
    "y_ub_1_tvm = tvm.nd.empty((length, dim_Y_out), device=dev)\n",
    "y_ub_tvm = tvm.nd.empty((length, dim_Y_out), device=dev)\n",
    "y_lw_1_tvm = tvm.nd.empty((length, dim_in, dim_Y_out), device=dev)\n",
    "y_lw_tvm = tvm.nd.empty((length, dim_in, dim_Y_out), device=dev)\n",
    "y_uw_1_tvm = tvm.nd.empty((length, dim_in, dim_Y_out), device=dev)\n",
    "y_uw_tvm = tvm.nd.empty((length, dim_in, dim_Y_out), device=dev)\n",
    "\n",
    "# Inference with ansor kernel\n",
    "func_lb1(W_tvm, x_lb_tvm, y_lb_1_tvm)\n",
    "func_lb2(W_tvm, x_ub_tvm, y_lb_1_tvm, y_lb_tvm)\n",
    "func_ub1(W_tvm, x_ub_tvm, y_ub_1_tvm)\n",
    "func_ub2(W_tvm, x_lb_tvm, y_ub_1_tvm, y_ub_tvm)\n",
    "func_lw1(W_tvm, x_lw_tvm, y_lw_1_tvm)\n",
    "func_lw2(W_tvm, x_uw_tvm, y_lw_1_tvm, y_lw_tvm)\n",
    "func_uw1(W_tvm, x_uw_tvm, y_uw_1_tvm)\n",
    "func_uw2(W_tvm, x_lw_tvm, y_uw_1_tvm, y_uw_tvm)\n",
    "\n",
    "# Compare ansor with tvm\n",
    "def check_tvm_ansor_baseline_diff(bound, y_lb_np, y_ub_np, y_lw_np, y_uw_np, device=\"cuda\"):\n",
    "    print(\"pytorch lb: \", bound.lb)\n",
    "    print(\"ansor lb: \", y_lb_np)\n",
    "    lb_diff = torch.norm((bound.lb- (torch.from_numpy(y_lb_np).to(device))))\n",
    "    ub_diff = torch.norm((bound.ub- (torch.from_numpy(y_ub_np).to(device))))\n",
    "    lw_diff = torch.norm((bound.lw- (torch.from_numpy(y_lw_np).to(device))))\n",
    "    uw_diff = torch.norm((bound.uw- (torch.from_numpy(y_uw_np).to(device))))\n",
    "    print(\"lb_diff: \", lb_diff, \", ub_diff: \", ub_diff, \", lw_diff: \", lw_diff, \", uw_diff: \", uw_diff)\n",
    "\n",
    "check_tvm_ansor_baseline_diff(\n",
    "    bound=bound,\n",
    "    y_lb_np=y_lb_tvm.numpy(),\n",
    "    y_ub_np=y_ub_tvm.numpy(),\n",
    "    y_lw_np=y_lw_tvm.numpy(),\n",
    "    y_uw_np=y_uw_tvm.numpy(),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
